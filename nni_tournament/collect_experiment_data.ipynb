{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Notebook to plot and organize CuteChess metrics form a nni experiment\n",
    "<br>Files to run the NNI-Experiment are expected to be in the same directory<br />\n",
    "<br>tournament_loop.py : main loop<br />\n",
    "<br>tournament_config.py : config used for the Cute Chess Tournament<br />\n",
    "<br>config.yml : config starting the NNI experiment<br />\n",
    "<br>search_space.json : declaring the Search Space for the hyperparameter tuner<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "nni_config = r\"C:\\Users\\Daniel\\MPVCrazyAra\\CrazyAra\\nni_tournament\\config.yml\"\n",
    "search_space = r\"C:\\Users\\Daniel\\MPVCrazyAra\\CrazyAra\\nni_tournament\\search_space.json\"\n",
    "\n",
    "## engine names  (elo diff from contender perspective)\n",
    "baseline_name = \"CrazyAra_Standard\"\n",
    "contender_name = \"MPV_Large_Standard\"##\"CrazyAra_RISEv2_27_blocks\"\n",
    "\n",
    "start_experiment_from_notebook = False ## assumes no experiment is currently running\n",
    "nni_refresh_rate = 30 ## refresh rate of experiment in seconds\n",
    "plot_metric = \"LargeNet_Policy_Weight\"\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from tournament_config import tournament_config\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import glob\n",
    "import os\n",
    "import configparser\n",
    "import re\n",
    "from pathlib import Path\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if start_experiment_from_notebook:\n",
    "    !nnictl create --config $nni_config\n",
    "\n",
    "    try:\n",
    "        experiment = !nnictl experiment show\n",
    "        experiment = (''.join(experiment)).replace(\" \",\"\")\n",
    "        experiment = json.loads(experiment)\n",
    "\n",
    "        experiment_path = experiment[\"logDir\"]\n",
    "        experiment_id = experiment[\"id\"]\n",
    "\n",
    "        experiment_status = \"RUNNING\"\n",
    "\n",
    "        while experiment_status == \"RUNNING\" or experiment_status == \"INITIALIZED\":\n",
    "            time.sleep(nni_refresh_rate)\n",
    "            experiment_status = !nnictl experiment status\n",
    "            experiment_status = (''.join(experiment_status)).replace(\" \",\"\")\n",
    "            experiment_status = json.loads(experiment_status)[\"status\"]\n",
    "\n",
    "        if experiment_status != \"FINISHED\": #in case of error / no more tuner trials\n",
    "            !nnictl stop $experiment_id\n",
    "\n",
    "    except Exception as exception:\n",
    "        !nnictl stop $experiment_id\n",
    "        raise exception\n",
    "\n",
    "else:\n",
    "    ## path to experiment directory\n",
    "    experiment_path = r\"C:\\Users\\Daniel\\nni-experiments\\n1FUHlwO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trials_path = experiment_path + r\"\\trials\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Cute Chess Tournament config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Fixed configs used for all Cute Chess Tournement startet during the nni experiment\n"
    }
   },
   "outputs": [],
   "source": [
    "pprint(tournament_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Create a dictonary containing the parameter + metrics for all trials in the experiment\n"
    }
   },
   "outputs": [],
   "source": [
    "##dict containing all trials with key of the fixed_movetime\n",
    "experiment_dict = {}\n",
    "\n",
    "plot_metrics = list()\n",
    "## iterate over all trials\n",
    "parser = configparser.ConfigParser()\n",
    "for trial in os.scandir(trials_path):\n",
    "    parameter_file = open(Path(trial.path + r\"\\parameter.cfg\"))\n",
    "    metric_file = open(Path(trial.path + r\"\\.nni\\metrics\"))\n",
    "    parameter = json.loads(parameter_file.read())['parameters']\n",
    "    test = metric_file.read()\n",
    "    metric = re.findall(r\"[{][\\s\\S]*[}]\", test)\n",
    "\n",
    "    if metric:\n",
    "        metric = metric[0]\n",
    "        metric = ast.literal_eval(metric)\n",
    "        metric = json.loads(metric['value'])\n",
    "\n",
    "    ## configure dict for trial, containing metrics (elo+var) and settings\n",
    "    trial_dict = {}\n",
    "    trial_dict.update(parameter)\n",
    "    if metric:\n",
    "        trial_dict['elo'] = float(metric['elo'])\n",
    "        trial_dict['variance'] = float(metric['variance'])\n",
    "    else:\n",
    "        trial_dict['elo'] = 'inf'\n",
    "        trial_dict['variance'] = 'nan'\n",
    "\n",
    "    plot_metrics.append(parameter[plot_metric])\n",
    "\n",
    "\n",
    "    if parameter[plot_metric] not in experiment_dict:\n",
    "        experiment_dict[parameter[plot_metric]] = list()\n",
    "    experiment_dict[parameter[plot_metric]].append(trial_dict)\n",
    "## add plot metrics to the dict\n",
    "experiment_dict[plot_metric] = plot_metrics\n",
    "experiment_dict['CuteChessConfig'] = tournament_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Plot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%  Plot settings\n"
    }
   },
   "outputs": [],
   "source": [
    "print(plt.style.available)\n",
    "# plt.style.use('seaborn-paper')\n",
    "plt.style.use('grayscale')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# plt.style.use('seaborn-white')\n",
    "#plt.style.use('fivethirtyeight')\n",
    "rc('font', **{'family': 'serif'})  # ,'sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "# rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "# rc('text', usetex=True)\n",
    "# print(plt.rcParams.keys())\n",
    "plt.rcParams['legend.frameon'] = 'True'\n",
    "plt.rcParams['legend.framealpha'] = '1.0'\n",
    "print(plt.rcParams['figure.figsize'])\n",
    "plt.rcParams['figure.figsize'] = [6.4*0.7, 4.8*0.7] #(15, 5)\n",
    "plt.rcParams['axes.grid.axis'] = 'y' #False\n",
    "# https://matplotlib.org/3.1.0/gallery/lines_bars_and_markers/linestyles.html\n",
    "linestyle_str = [\n",
    "  ('solid', 'solid'),  # Same as (0, ()) or '-'\n",
    "  ('dotted', 'dotted'),  # Same as (0, (1, 1)) or '.'\n",
    "  ('dashed', 'dashed'),  # Same as '--'\n",
    "  ('dashdot', 'dashdot')]  # Same as '-.'\n",
    "linestyle_tuple = [\n",
    "  ('loosely dotted', (0, (1, 10))),\n",
    "  ('dotted', (0, (1, 1))),\n",
    "  ('densely dotted', (0, (1, 1))),\n",
    "\n",
    "  ('loosely dashed', (0, (5, 10))),\n",
    "  ('dashed', (0, (5, 5))),\n",
    "  ('densely dashed', (0, (5, 1))),\n",
    "\n",
    "  ('loosely dashdotted', (0, (3, 10, 1, 10))),\n",
    "  ('dashdotted', (0, (3, 5, 1, 5))),\n",
    "  ('densely dashdotted', (0, (3, 1, 1, 1))),\n",
    "\n",
    "  ('dashdotdotted', (0, (3, 5, 1, 5, 1, 5))),\n",
    "  ('loosely dashdotdotted', (0, (3, 10, 1, 10, 1, 10))),\n",
    "  ('densely dashdotdotted', (0, (3, 1, 1, 1, 1, 1)))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prepare Data for Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Prepare Data\n"
    }
   },
   "outputs": [],
   "source": [
    "x = experiment_dict[plot_metric]\n",
    "x.sort()\n",
    "elo =  list()\n",
    "variance = list()\n",
    "\n",
    "for timestamp in x:\n",
    "    elo_tmp = []\n",
    "    var_tmp = []\n",
    "    settings = experiment_dict[timestamp]\n",
    "    for plot_setting in settings:\n",
    "        elo_tmp.append(float(plot_setting['elo']))\n",
    "        var_tmp.append(float(plot_setting['variance']))\n",
    "    elo.append(elo_tmp)\n",
    "    variance.append(var_tmp)\n",
    "\n",
    "elo = np.column_stack(elo).tolist()\n",
    "variance = np.column_stack(variance).tolist()\n",
    "\n",
    "## create Plot label\n",
    "plot_label =  list()\n",
    "for param in experiment_dict[x[0]]:\n",
    "    str_tmp = \"\"\n",
    "    for key in param.keys():\n",
    "        if key != plot_metric and key != 'elo' and key != 'variance': ## already stated\n",
    "            next_arg = \"\"\n",
    "            if isinstance(param[key],str):\n",
    "                if param[key] == 'true':\n",
    "                    next_arg = key\n",
    "            else: ## param is float (or int)\n",
    "                next_arg =  key + \" = \" + str(param[key])\n",
    "            if next_arg:\n",
    "                if not str_tmp:\n",
    "                    str_tmp = next_arg\n",
    "                else:\n",
    "                    str_tmp = str_tmp + \"; \" + next_arg\n",
    "    plot_label.append(str_tmp)\n",
    "## add elo and var to experiment dict for better access later\n",
    "experiment_dict['plot_data'] = {'x': x, 'elo': elo, 'var': variance, 'label': plot_label, 'contender_name': contender_name, 'baseline_name': baseline_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Plot\n"
    }
   },
   "outputs": [],
   "source": [
    "figures = list()\n",
    "plot_data = experiment_dict['plot_data']\n",
    "for elo_plt, var_plt, label in zip(np.array(plot_data['elo']), np.array(plot_data['var']), np.array(plot_data['label'])):\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle(\"{} vs. {}\".format(plot_data['contender_name'], plot_data['baseline_name']))\n",
    "    plt.grid(True)\n",
    "\n",
    "    if label:\n",
    "        fig.text(0, -0.05, \"Additional Settings:\")\n",
    "        fig.text(0,-0.10,label)\n",
    "\n",
    "    plt.xticks(x)\n",
    "    plt.xlabel(plot_metric)\n",
    "    plt.ylabel(\"Relative elo difference\")\n",
    "    plt.plot(x, elo_plt, label=\"elo difference between: \\n {} \\n {}\".format(contender_name, baseline_name))\n",
    "    plt.fill_between(x, elo_plt - var_plt, elo_plt + var_plt, color='black', alpha=0.25)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    figures.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Save Plots + Data as dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Save processed Data + Plots in experiment Dir\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_data_dir = experiment_path + r\"\\plot_data\"\n",
    "if not os.path.isdir(plot_data_dir):\n",
    "    os.mkdir(plot_data_dir)\n",
    "\n",
    "with open(plot_data_dir + r'\\experiment_data.json', 'w') as file:\n",
    "    json.dump(experiment_dict, file, indent=len(x))\n",
    "\n",
    "for fig, plot_num in zip(figures,  np.arange(len(figures))):\n",
    "    fig.savefig(plot_data_dir + r\"\\{}_vs_{}_{}.pdf\".format(contender_name, baseline_name, plot_num), bbox_inches=\"tight\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}